{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "Pg5D9dah5Njo"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Importing all necessary libraries\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        "\n",
        "img_width, img_height = 224, 224"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_data_dir = '/content/drive/MyDrive/ML/CarPlaneClassification/train'\n",
        "validation_data_dir = '/content/drive/MyDrive/ML/CarPlaneClassification/test'\n",
        "nb_train_samples =400\n",
        "nb_validation_samples = 100\n",
        "epochs = 10\n",
        "batch_size = 16"
      ],
      "metadata": {
        "id": "fE6DcXj067oH"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_shape = (img_width, img_height, 3)"
      ],
      "metadata": {
        "id": "4whi6CZXFuDf"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (2, 2), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n"
      ],
      "metadata": {
        "id": "3hjwg84SG3VM"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "1O5rWcG6bS2N"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "\trescale=1. / 255,\n",
        "\tshear_range=0.2,\n",
        "\tzoom_range=0.2,\n",
        "\thorizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "\ttrain_data_dir,\n",
        "\ttarget_size=(img_width, img_height),\n",
        "\tbatch_size=batch_size,\n",
        "\tclass_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "\tvalidation_data_dir,\n",
        "\ttarget_size=(img_width, img_height),\n",
        "\tbatch_size=batch_size,\n",
        "\tclass_mode='binary')\n",
        "\n",
        "model.fit_generator(\n",
        "\ttrain_generator,\n",
        "\tsteps_per_epoch=nb_train_samples // batch_size,\n",
        "\tepochs=epochs,\n",
        "\tvalidation_data=validation_generator,\n",
        "\tvalidation_steps=nb_validation_samples // batch_size)\n"
      ],
      "metadata": {
        "id": "driPtMhSLmSt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63bfcdf5-c65f-49e3-a7ae-320e712b35f8"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400 images belonging to 2 classes.\n",
            "Found 100 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-50-e400c965663a>:21: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "25/25 [==============================] - 18s 673ms/step - loss: 0.9241 - accuracy: 0.5950 - val_loss: 0.4683 - val_accuracy: 0.8646\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 17s 663ms/step - loss: 0.5470 - accuracy: 0.7675 - val_loss: 0.3475 - val_accuracy: 0.8750\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 17s 675ms/step - loss: 0.5312 - accuracy: 0.7800 - val_loss: 0.3569 - val_accuracy: 0.8646\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 18s 722ms/step - loss: 0.4043 - accuracy: 0.8325 - val_loss: 0.2729 - val_accuracy: 0.8854\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 17s 664ms/step - loss: 0.4118 - accuracy: 0.8300 - val_loss: 0.3543 - val_accuracy: 0.8021\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 18s 711ms/step - loss: 0.3509 - accuracy: 0.8425 - val_loss: 0.3202 - val_accuracy: 0.8646\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 17s 689ms/step - loss: 0.3310 - accuracy: 0.8850 - val_loss: 0.3806 - val_accuracy: 0.8229\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 18s 715ms/step - loss: 0.2860 - accuracy: 0.8825 - val_loss: 0.4839 - val_accuracy: 0.8125\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 17s 668ms/step - loss: 0.2937 - accuracy: 0.8825 - val_loss: 0.5433 - val_accuracy: 0.7292\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 19s 763ms/step - loss: 0.2984 - accuracy: 0.8925 - val_loss: 0.3296 - val_accuracy: 0.8438\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8711cf4880>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(train_generator,batch_size=16)\n",
        "print(\"Resnet50 model, accuracy: {:5.2f}%\".format(100 * acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpnFxzXFqP4H",
        "outputId": "e2458134-99bb-4a96-bd89-429d13ad6627"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 7s 288ms/step - loss: 0.2516 - accuracy: 0.8850\n",
            "Resnet50 model, accuracy: 88.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.applications.vgg16 import decode_predictions\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "image = load_img('/content/drive/MyDrive/ML/CarPlaneClassification/test/cars/14.jpg', target_size=(224, 224))\n",
        "img = np.array(image)\n",
        "img = img / 255.0\n",
        "img = img.reshape(1,224,224,3)\n",
        "label = model.predict(img)\n",
        "print(\"Predicted Class (0 - Cars , 1- Planes): \", label[0][0])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FGkr2SeilrI",
        "outputId": "c5d74dd3-70b0-434b-cece-75bd46f0e270"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n",
            "Predicted Class (0 - Cars , 1- Planes):  0.00028739992\n"
          ]
        }
      ]
    }
  ]
}